Universe        = vanilla
Executable      = wrapper_dps.sh
Arguments       = $(LHE) $(MINIAOD) $(x509userproxy) $(EXTRA_ARGS)
Output          = logs/job_$(JobId)_$(ClusterId).stdout
Error           = logs/job_$(JobId)_$(ClusterId).stderr
Log             = logs/job_$(JobId)_$(ClusterId).log

# These lines transfer the wrapper and required files to the worker node.
should_transfer_files   = YES
when_to_transfer_output = ON_EXIT
transfer_input_files    = wrapper_dps.sh,\
                          HadronizerGENSIM_13p6TeV_TuneCP5_pythia8_Run3Summer22.py,\
                          HepMC_GENSIM_13p6TeV_Run3Summer22.py,\
                          DIGI_13p6TeV_TuneCP5_pythia8_Run3Summer22.py,\
                          RECO_13p6TeV_TuneCP5_pythia8_Run3Summer22.py,\
                          Mini_13p6TeV_TuneCP5_pythia8_Run3Summer22.py,\
                          pythia8_lhe_to_hepmc.cc,\
                          pythia8_lhe_to_hepmc.cmnd,\
                          Makefile.pythia8,\
                          build_pythia8.sh,\
                          event_splitter.cpp,\
                          Makefile.splitter,\
                          merge_hepmc.sh

# Increase resource requests for DPS workflow
# DPS workflow requires more disk space for LHE chunks and HepMC files
request_cpus    = 4
request_memory  = 16 GB
request_disk    = 8 GB
+JobFlavour     = "workday"

# If your jobs require a proxy to access EOS, set it up like this:
x509userproxy = /afs/cern.ch/user/c/chiw/condor/x509up

# Queue jobs using an extended file format:
# LHE_file MINIAOD_output [EXTRA_ARGS]
# EXTRA_ARGS can be empty or contain: --keep-hepmc --hepmc-dir <dir> --no-dps
# Examples:
#   /path/to/input.lhe /path/to/output.root
#   /path/to/input.lhe /path/to/output.root --keep-hepmc
#   /path/to/input.lhe /path/to/output.root --keep-hepmc --hepmc-dir /path/to/hepmc_dir
queue LHE, MINIAOD, EXTRA_ARGS from LHE_sources.txt
